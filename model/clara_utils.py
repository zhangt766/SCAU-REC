# -*- coding: utf-8 -*-
"""clara_utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11qTK3oBGTP4cwpMrKS4kCd3lwhSlWGbR
"""

# clara_utils.py
# ============================================================
# CLARA utilities (B-mode):
# - ranking metrics (Hit@K / NDCG@K / MRR@K)
# - candidate scoring (MVP: first-token prob; pluggable)
# - per-user state container (coreset + subspace basis Q + stats)
# - drift trigger: d_t, u_t, lambda_t
# - coreset update/prune
# - risk-aware alignment: symmetric KL (cheap on candidate distribution)
# - safe-subspace projection: maintain Q and project gradients
#
# Notes:
# 1) This file is "CLARA-MVP": it is runnable and modular, but uses cheap proxies
#    (candidate distribution over candidate list instead of full vocab).
# 2) You can later replace scoring with sequence logprob or special item tokens
#    without touching the rest of the code.
# ============================================================

from __future__ import annotations

from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple, Iterable

import numpy as np
import pandas as pd
import torch
from torch.nn import functional as F


# ============================================================
# 0) Small helpers
# ============================================================

def to_device_batch(batch: Dict[str, Any], device: torch.device) -> Dict[str, Any]:
    """Move tensor fields in batch to device."""
    out = {}
    for k, v in batch.items():
        if torch.is_tensor(v):
            out[k] = v.to(device)
        else:
            out[k] = v
    return out


def l2_normalize(x: torch.Tensor, eps: float = 1e-12) -> torch.Tensor:
    return x / (x.norm(dim=-1, keepdim=True) + eps)


def cosine_distance(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:
    """
    a: [d] or [1,d]
    b: [n,d]
    return: [n]  distance = 1 - cos
    """
    if a.dim() == 1:
        a = a.unsqueeze(0)  # [1,d]
    a = l2_normalize(a)
    b = l2_normalize(b)
    # broadcast to [n,d] then sum -> [n]
    cos = (a * b).sum(dim=-1)
    return 1.0 - cos


# ============================================================
# 1) Ranking metrics
# ============================================================

def evaluate_ranking_metrics(scored_df: pd.DataFrame, ks: Iterable[int] = (5, 10)) -> Dict[str, float]:
    """
    scored_df must contain columns: sample_id, prob, label
    Assumption: one positive per sample in next-item ranking.

    Returns:
      hit@k, ndcg@k, mrr@k for each k
    """
    ks = list(ks)
    if scored_df is None or len(scored_df) == 0:
        return {f"{m}@{k}": 0.0 for k in ks for m in ["hit", "ndcg", "mrr"]}

    df = scored_df.sort_values(["sample_id", "prob"], ascending=[True, False])
    groups = df.groupby("sample_id", sort=False)

    out: Dict[str, float] = {}
    for k in ks:
        hit_sum = 0.0
        ndcg_sum = 0.0
        mrr_sum = 0.0
        n = 0

        for _, g in groups:
            labels = g["label"].to_numpy(dtype=np.int32)
            if labels.size == 0:
                continue
            n += 1

            # Hit@k
            topk = labels[:k]
            hit_sum += 1.0 if (topk.max(initial=0) == 1) else 0.0

            # NDCG / MRR (single positive)
            if 1 in labels:
                rank0 = int(np.where(labels == 1)[0][0])  # 0-index
                rank = rank0 + 1
                if rank <= k:
                    ndcg_sum += 1.0 / np.log2(rank + 1.0)
                    mrr_sum += 1.0 / rank

        out[f"hit@{k}"] = hit_sum / n if n > 0 else 0.0
        out[f"ndcg@{k}"] = ndcg_sum / n if n > 0 else 0.0
        out[f"mrr@{k}"] = mrr_sum / n if n > 0 else 0.0

    return out


# ============================================================
# 2) Per-user state for CLARA
# ============================================================

@dataclass
class UserState:
    # Reference coreset: list of [d] embeddings (CPU tensors)
    bref_embs: List[torch.Tensor] = field(default_factory=list)

    # Safe-subspace basis Q: [d, r] on CPU (optional)
    Q: Optional[torch.Tensor] = None

    # Stats
    steps: int = 0
    trigger_count: int = 0
    avg_drift: float = 0.0
    avg_lambda: float = 0.0

    def update_stats(self, d_t: float, lam: float, triggered: bool):
        self.steps += 1
        if triggered:
            self.trigger_count += 1
        # running average
        self.avg_drift = self.avg_drift + (d_t - self.avg_drift) / max(1, self.steps)
        self.avg_lambda = self.avg_lambda + (lam - self.avg_lambda) / max(1, self.steps)


# ============================================================
# 3) Candidate scoring (MVP) + rows for DataFrame
# ============================================================

@torch.no_grad()
def score_candidates_token_first(
    model,
    batch: Dict[str, Any],
    batch_idx: int,
    temperature: float = 1.0,
) -> List[Dict[str, Any]]:
    """
    Minimal scoring for ranking metrics:
    - forward pass
    - use next-token distribution at last position
    - score each candidate by prob of the FIRST token of its title
    - label uses candidate_id == target_id (stable and correct)

    Requires batch contains:
      tokens, cans_name, cans (ids), item_id
    Optional:
      user_id, t
    """
    out = model(batch)
    logits = out.logits[:, -1, :]  # [B, V]
    probs = F.softmax(logits / max(1e-6, float(temperature)), dim=-1)

    B = logits.size(0)
    rows: List[Dict[str, Any]] = []

    has_uid = "user_id" in batch
    has_t = "t" in batch

    for i in range(B):
        target_id = int(batch["item_id"][i].item())
        uid = int(batch["user_id"][i].item()) if has_uid else None
        tt = int(batch["t"][i].item()) if has_t else None

        cand_ids = batch["cans"][i]          # tensor [C]
        cand_names = batch["cans_name"][i]   # list[str]

        for j, can_name in enumerate(cand_names):
            token_ids = model.llama_tokenizer(can_name, add_special_tokens=False).input_ids
            if len(token_ids) == 0:
                continue
            token_id = token_ids[0]
            prob = float(probs[i, token_id].item())

            cand_id = int(cand_ids[j].item())
            label = 1 if cand_id == target_id else 0

            row = {
                "sample_id": batch_idx * B + i,
                "candidate": can_name,
                "candidate_id": cand_id,
                "target_id": target_id,
                "prob": prob,
                "label": label,
            }
            if uid is not None:
                row["user_id"] = uid
            if tt is not None:
                row["t"] = tt
            rows.append(row)

    return rows


# ============================================================
# 4) Drift trigger + lambda schedule
# ============================================================

@torch.no_grad()
def extract_query_embedding(
    model,
    batch: Dict[str, Any],
    i: int,
    mode: str = "last",
) -> torch.Tensor:
    """
    Define h_t used for drift detection.

    mode:
      - "last": last history item embedding
      - "mean": mean of history embeddings

    Requires batch:
      seq: [B, L]
      len_seq: [B]
    """
    # [B, L, d]
    his_item_embeds = model.encode_items(batch["seq"])
    li = int(batch["len_seq"][i].item())
    li = max(1, li)

    if mode == "mean":
        h = his_item_embeds[i, :li, :].mean(dim=0)
    else:
        h = his_item_embeds[i, li - 1, :]
    return h.detach()


def compute_drift_score_from_coreset(h_t: torch.Tensor, bref: List[torch.Tensor]) -> float:
    """
    bref: list of [d] CPU tensors
    d_t: min cosine distance to coreset elements (closest reference)
    """
    if bref is None or len(bref) == 0:
        return 0.0
    B = torch.stack([v.to(h_t.device) for v in bref], dim=0)  # [n, d]
    dist = cosine_distance(h_t, B)  # [n]
    return float(dist.min().item())


def trigger_from_drift(d_t: float, tau: float) -> int:
    return int(d_t > tau)


def lambda_from_drift(
    d_t: float,
    tau: float,
    lambda_max: float,
    mode: str = "linear",
) -> float:
    """
    Adaptive alignment strength Î»_t.

    MVP schedule:
      - if not triggered: 0
      - else: scaled by (d_t - tau)
    """
    if d_t <= tau:
        return 0.0
    x = d_t - tau
    if mode == "linear":
        return float(min(lambda_max, lambda_max * x / max(1e-6, tau)))
    if mode == "tanh":
        return float(lambda_max * np.tanh(x))
    return float(lambda_max)


# ============================================================
# 5) Coreset update / prune
# ============================================================

def update_coreset_fifo(bref: List[torch.Tensor], h_t: torch.Tensor, max_size: int) -> List[torch.Tensor]:
    """MVP: FIFO buffer update."""
    if bref is None:
        bref = []
    bref.append(h_t.detach().cpu())
    if len(bref) > int(max_size):
        bref = bref[-int(max_size):]
    return bref


def prune_coreset_by_diversity(bref: List[torch.Tensor], max_size: int, eps: float = 0.05) -> List[torch.Tensor]:
    """
    Optional prune: keep a diverse set by removing near-duplicates (cos distance < eps).
    Greedy: iterate in order, keep if far enough from kept.
    """
    max_size = int(max_size)
    if len(bref) <= max_size:
        return bref

    keep: List[torch.Tensor] = []
    for v in bref:
        if len(keep) == 0:
            keep.append(v)
            continue
        B = torch.stack(keep, dim=0)
        d = float(cosine_distance(v.to(B.device), B).min().item())
        if d >= eps:
            keep.append(v)
        if len(keep) >= max_size:
            break

    # if still short, fill with recent
    if len(keep) < max_size:
        for v in reversed(bref):
            if len(keep) >= max_size:
                break
            keep.append(v)
    return keep[:max_size]


# ============================================================
# 6) Risk-aware alignment: symmetric KL on candidate distribution
# ============================================================

def symmetric_kl(p: torch.Tensor, q: torch.Tensor, eps: float = 1e-12) -> torch.Tensor:
    """
    p,q: [C] distributions
    return scalar tensor
    """
    p = torch.clamp(p, eps, 1.0)
    q = torch.clamp(q, eps, 1.0)
    kl_pq = (p * (p.log() - q.log())).sum()
    kl_qp = (q * (q.log() - p.log())).sum()
    return kl_pq + kl_qp


@torch.no_grad()
def candidate_distribution_first_token(
    model,
    batch: Dict[str, Any],
    i: int,
    temperature: float = 1.0,
) -> torch.Tensor:
    """
    Produce probability distribution over candidates (C items) for sample i.
    MVP uses first-token prob for each candidate title, then renormalizes over candidates.

    Returns dist: [C] (sums to 1)
    """
    out = model(batch)
    logits = out.logits[:, -1, :]  # [B, V]
    probs_vocab = F.softmax(logits / max(1e-6, float(temperature)), dim=-1)

    cand_names = batch["cans_name"][i]
    scores = []
    for can in cand_names:
        token_ids = model.llama_tokenizer(can, add_special_tokens=False).input_ids
        if len(token_ids) == 0:
            scores.append(0.0)
            continue
        tid = token_ids[0]
        scores.append(float(probs_vocab[i, tid].item()))
    scores_t = torch.tensor(scores, device=logits.device, dtype=torch.float32)
    dist = scores_t / (scores_t.sum() + 1e-12)
    return dist


# ============================================================
# 7) Safe-subspace projection (simplified online)
# ============================================================

def update_subspace_Q(Q: Optional[torch.Tensor], g: torch.Tensor, r: int) -> torch.Tensor:
    """
    Maintain an orthonormal basis Q of top-r directions (simplified):
      - append normalized g to existing basis vectors
      - QR to re-orthonormalize
      - truncate to r

    g: [d] (flattened gradient vector)
    Q: [d, r_old] or None

    Returns: Q_new on the same device as g
    """
    r = int(r)
    g = g.detach()
    g = g / (g.norm() + 1e-12)

    if Q is None:
        return g.unsqueeze(1)  # [d,1]

    M = torch.cat([Q, g.unsqueeze(1)], dim=1)  # [d, r_old+1]
    Q_new, _ = torch.linalg.qr(M, mode="reduced")  # [d, r_old+1]
    if Q_new.size(1) > r:
        Q_new = Q_new[:, :r]
    return Q_new


def project_gradient_orthogonal(g: torch.Tensor, Q: Optional[torch.Tensor]) -> torch.Tensor:
    """
    g_perp = (I - Q Q^T) g
    g: [d]
    Q: [d, r]
    """
    if Q is None:
        return g
    proj = Q @ (Q.t() @ g)
    return g - proj


# ============================================================
# 8) Utilities for gradients / parameter vectorization (for LoRA params)
# ============================================================

def iter_trainable_params(model: torch.nn.Module) -> List[torch.nn.Parameter]:
    """Return parameters requiring grad (trainable)."""
    return [p for p in model.parameters() if p.requires_grad]


def flatten_grads(params: List[torch.nn.Parameter]) -> torch.Tensor:
    """Flatten grads into a single vector [d]. Missing grads treated as zeros."""
    vecs = []
    for p in params:
        if p.grad is None:
            vecs.append(torch.zeros_like(p).view(-1))
        else:
            vecs.append(p.grad.detach().view(-1))
    return torch.cat(vecs, dim=0)


def apply_projected_grads(params: List[torch.nn.Parameter], g_proj: torch.Tensor):
    """
    Overwrite params' gradients using flattened projected gradient.
    This lets you keep your existing optimizer.step().

    params: list of trainable parameters
    g_proj: [d] flattened gradient
    """
    offset = 0
    for p in params:
        numel = p.numel()
        g_slice = g_proj[offset: offset + numel].view_as(p)
        if p.grad is None:
            p.grad = torch.zeros_like(p)
        p.grad.copy_(g_slice)
        offset += numel
    assert offset == g_proj.numel()


# ============================================================
# 9) One-step CLARA decision helper (no optimizer inside)
# ============================================================

@torch.no_grad()
def clara_decide_trigger_and_update_coreset(
    model,
    state: UserState,
    batch: Dict[str, Any],
    i: int,
    tau: float,
    lambda_max: float,
    bref_max_size: int,
    embed_mode: str = "last",
    lambda_mode: str = "linear",
    prune: bool = False,
    prune_eps: float = 0.05,
) -> Tuple[float, int, float]:
    """
    Returns (d_t, u_t, lambda_t) and also updates coreset in the state.

    This is pure "trigger + coreset maintenance" part.
    """
    h_t = extract_query_embedding(model, batch, i, mode=embed_mode)
    d_t = compute_drift_score_from_coreset(h_t, state.bref_embs)
    u_t = trigger_from_drift(d_t, tau)
    lam = lambda_from_drift(d_t, tau, lambda_max, mode=lambda_mode)

    # update coreset
    state.bref_embs = update_coreset_fifo(state.bref_embs, h_t, max_size=bref_max_size)
    if prune:
        state.bref_embs = prune_coreset_by_diversity(state.bref_embs, max_size=bref_max_size, eps=prune_eps)

    state.update_stats(d_t=d_t, lam=lam, triggered=bool(u_t))
    return d_t, u_t, lam